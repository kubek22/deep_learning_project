{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:07:22.930994Z",
     "start_time": "2025-03-12T17:07:22.904703Z"
    }
   },
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from data_loader import load_datasets, create_data_loaders\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from training_pipeline import repeat_training, train_with_different_parameters\n",
    "from serialization import load\n",
    "from cnn_model import Net\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:07:24.199819Z",
     "start_time": "2025-03-12T17:07:24.175202Z"
    }
   },
   "source": [
    "batch_size = 64"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:07:25.159350Z",
     "start_time": "2025-03-12T17:07:24.697757Z"
    }
   },
   "source": [
    "train, val, test = load_datasets((32, 32))\n",
    "train_dat, val_dat, test_dat = create_data_loaders(train, val, test, batch_size)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning rate test"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-03-12T17:59:19.231535Z",
     "start_time": "2025-03-12T17:07:27.355425Z"
    }
   },
   "source": "train_with_different_parameters(5, Net, 10, train_dat, val_dat, test_dat, 'cuda', batch_size, lrs=[i/500 for i in range(1,6)])",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training iteration: 1 of 5\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.027597502557436624, training accuracy: 32.95\n",
      "epoch: 1, validation loss: 1.561639573838976e-05, validation accuracy: 42.36\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.024815207991335127, training accuracy: 40.31111111111111\n",
      "epoch: 2, validation loss: 1.767778793970744e-05, validation accuracy: 45.138888888888886\n",
      "\n",
      "epoch: 3, training loss: 0.02394002435074912, training accuracy: 42.57666666666667\n",
      "epoch: 3, validation loss: 1.189122862286038e-05, validation accuracy: 46.85444444444445\n",
      "model saved\n",
      "\n",
      "epoch: 4, training loss: 0.02345799659093221, training accuracy: 44.13111111111111\n",
      "epoch: 4, validation loss: 1.2407444583045112e-05, validation accuracy: 49.50888888888889\n",
      "\n",
      "epoch: 5, training loss: 0.023075528967380524, training accuracy: 45.193333333333335\n",
      "epoch: 5, validation loss: 1.492825878991021e-05, validation accuracy: 48.67888888888889\n",
      "\n",
      "epoch: 6, training loss: 0.022818227769268885, training accuracy: 46.06444444444445\n",
      "epoch: 6, validation loss: 1.6625743442111544e-05, validation accuracy: 48.92444444444445\n",
      "\n",
      "epoch: 7, training loss: 0.022632220145728854, training accuracy: 46.64222222222222\n",
      "epoch: 7, validation loss: 1.2541498078240289e-05, validation accuracy: 51.03333333333333\n",
      "\n",
      "epoch: 8, training loss: 0.022402285419570074, training accuracy: 47.284444444444446\n",
      "epoch: 8, validation loss: 1.4706012937757703e-05, validation accuracy: 51.91444444444444\n",
      "\n",
      "epoch: 9, training loss: 0.022210947517553967, training accuracy: 48.044444444444444\n",
      "epoch: 9, validation loss: 1.3645892673068576e-05, validation accuracy: 52.17444444444445\n",
      "\n",
      "epoch: 10, training loss: 0.022073237498601277, training accuracy: 48.56777777777778\n",
      "epoch: 10, validation loss: 1.1430005232493083e-05, validation accuracy: 52.913333333333334\n",
      "model saved\n",
      "\n",
      "training finished\n",
      "\n",
      "{'loss_train': [0.027597502557436624, 0.024815207991335127, 0.02394002435074912, 0.02345799659093221, 0.023075528967380524, 0.022818227769268885, 0.022632220145728854, 0.022402285419570074, 0.022210947517553967, 0.022073237498601277], 'accuracy_train': [32.95, 40.31111111111111, 42.57666666666667, 44.13111111111111, 45.193333333333335, 46.06444444444445, 46.64222222222222, 47.284444444444446, 48.044444444444444, 48.56777777777778], 'loss_val': [1.561639573838976e-05, 1.767778793970744e-05, 1.189122862286038e-05, 1.2407444583045112e-05, 1.492825878991021e-05, 1.6625743442111544e-05, 1.2541498078240289e-05, 1.4706012937757703e-05, 1.3645892673068576e-05, 1.1430005232493083e-05], 'accuracy_val': [42.36, 45.138888888888886, 46.85444444444445, 49.50888888888889, 48.67888888888889, 48.92444444444445, 51.03333333333333, 51.91444444444444, 52.17444444444445, 52.913333333333334], 'last_save': 10}\n",
      "training time: 668.021806716919\n",
      "\n",
      "evaluating model...\n",
      "test loss: 1.139821211496989e-05, test accuracy: 53.01111111111111\n",
      "training history saved\n",
      "\n",
      "training iteration: 2 of 5\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.02705541548728943, training accuracy: 34.406666666666666\n",
      "epoch: 1, validation loss: 1.7205895317925347e-05, validation accuracy: 43.51111111111111\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.024431326166788735, training accuracy: 41.7\n",
      "epoch: 2, validation loss: 1.6903793811798094e-05, validation accuracy: 45.85111111111111\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 0.02354150859117508, training accuracy: 44.202222222222225\n",
      "epoch: 3, validation loss: 1.6663622856140138e-05, validation accuracy: 49.08777777777778\n",
      "model saved\n",
      "\n",
      "epoch: 4, training loss: 0.023095523195796542, training accuracy: 45.46\n",
      "epoch: 4, validation loss: 1.1445573965708415e-05, validation accuracy: 49.37222222222222\n",
      "model saved\n",
      "\n",
      "epoch: 5, training loss: 0.022643979528215195, training accuracy: 46.88111111111111\n",
      "epoch: 5, validation loss: 1.4217827055189345e-05, validation accuracy: 51.45666666666666\n",
      "\n",
      "epoch: 6, training loss: 0.022504240344630347, training accuracy: 47.16888888888889\n",
      "epoch: 6, validation loss: 1.3126275274488662e-05, validation accuracy: 50.32333333333333\n",
      "\n",
      "epoch: 7, training loss: 0.022258681836393145, training accuracy: 47.85333333333333\n",
      "epoch: 7, validation loss: 1.0455640157063801e-05, validation accuracy: 51.52444444444444\n",
      "model saved\n",
      "\n",
      "epoch: 8, training loss: 0.022038874864578246, training accuracy: 48.431111111111115\n",
      "epoch: 8, validation loss: 1.047078702184889e-05, validation accuracy: 52.397777777777776\n",
      "\n",
      "epoch: 9, training loss: 0.021914709050125547, training accuracy: 48.705555555555556\n",
      "epoch: 9, validation loss: 1.3595819473266601e-05, validation accuracy: 52.71888888888889\n",
      "\n",
      "epoch: 10, training loss: 0.021864220474825963, training accuracy: 49.068888888888885\n",
      "epoch: 10, validation loss: 1.1422798368665908e-05, validation accuracy: 53.05222222222222\n",
      "\n",
      "training finished\n",
      "\n",
      "{'loss_train': [0.02705541548728943, 0.024431326166788735, 0.02354150859117508, 0.023095523195796542, 0.022643979528215195, 0.022504240344630347, 0.022258681836393145, 0.022038874864578246, 0.021914709050125547, 0.021864220474825963], 'accuracy_train': [34.406666666666666, 41.7, 44.202222222222225, 45.46, 46.88111111111111, 47.16888888888889, 47.85333333333333, 48.431111111111115, 48.705555555555556, 49.068888888888885], 'loss_val': [1.7205895317925347e-05, 1.6903793811798094e-05, 1.6663622856140138e-05, 1.1445573965708415e-05, 1.4217827055189345e-05, 1.3126275274488662e-05, 1.0455640157063801e-05, 1.047078702184889e-05, 1.3595819473266601e-05, 1.1422798368665908e-05], 'accuracy_val': [43.51111111111111, 45.85111111111111, 49.08777777777778, 49.37222222222222, 51.45666666666666, 50.32333333333333, 51.52444444444444, 52.397777777777776, 52.71888888888889, 53.05222222222222], 'last_save': 7}\n",
      "training time: 639.470470905304\n",
      "\n",
      "evaluating model...\n",
      "test loss: 1.0733131567637126e-05, test accuracy: 51.343333333333334\n",
      "training history saved\n",
      "\n",
      "training iteration: 3 of 5\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.027264428497685327, training accuracy: 33.84\n",
      "epoch: 1, validation loss: 1.1658840709262424e-05, validation accuracy: 40.90888888888889\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.02442736914290322, training accuracy: 41.64555555555555\n",
      "epoch: 2, validation loss: 1.0500876108805338e-05, validation accuracy: 45.504444444444445\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 0.023412643627325695, training accuracy: 44.845555555555556\n",
      "epoch: 3, validation loss: 1.2377515104081896e-05, validation accuracy: 49.03\n",
      "\n",
      "epoch: 4, training loss: 0.022848336435688867, training accuracy: 46.17444444444445\n",
      "epoch: 4, validation loss: 1.4051891697777641e-05, validation accuracy: 50.68555555555555\n",
      "\n",
      "epoch: 5, training loss: 0.022476608521408505, training accuracy: 47.35666666666667\n",
      "epoch: 5, validation loss: 1.2053267161051433e-05, validation accuracy: 51.44777777777778\n",
      "\n",
      "epoch: 6, training loss: 0.02222360298368666, training accuracy: 48.272222222222226\n",
      "epoch: 6, validation loss: 1.3849571016099717e-05, validation accuracy: 53.04\n",
      "\n",
      "epoch: 7, training loss: 0.02186331641409132, training accuracy: 49.15111111111111\n",
      "epoch: 7, validation loss: 1.2936414612664117e-05, validation accuracy: 52.53111111111111\n",
      "\n",
      "epoch: 8, training loss: 0.02169211735063129, training accuracy: 49.70444444444445\n",
      "epoch: 8, validation loss: 1.1255372895134819e-05, validation accuracy: 53.60888888888889\n",
      "\n",
      "epoch: 9, training loss: 0.02150344805121422, training accuracy: 50.17777777777778\n",
      "epoch: 9, validation loss: 1.1835984388987224e-05, validation accuracy: 54.58444444444444\n",
      "\n",
      "epoch: 10, training loss: 0.021246043492688074, training accuracy: 50.83444444444444\n",
      "epoch: 10, validation loss: 1.0968434148364597e-05, validation accuracy: 54.5\n",
      "\n",
      "training finished\n",
      "\n",
      "{'loss_train': [0.027264428497685327, 0.02442736914290322, 0.023412643627325695, 0.022848336435688867, 0.022476608521408505, 0.02222360298368666, 0.02186331641409132, 0.02169211735063129, 0.02150344805121422, 0.021246043492688074], 'accuracy_train': [33.84, 41.64555555555555, 44.845555555555556, 46.17444444444445, 47.35666666666667, 48.272222222222226, 49.15111111111111, 49.70444444444445, 50.17777777777778, 50.83444444444444], 'loss_val': [1.1658840709262424e-05, 1.0500876108805338e-05, 1.2377515104081896e-05, 1.4051891697777641e-05, 1.2053267161051433e-05, 1.3849571016099717e-05, 1.2936414612664117e-05, 1.1255372895134819e-05, 1.1835984388987224e-05, 1.0968434148364597e-05], 'accuracy_val': [40.90888888888889, 45.504444444444445, 49.03, 50.68555555555555, 51.44777777777778, 53.04, 52.53111111111111, 53.60888888888889, 54.58444444444444, 54.5], 'last_save': 2}\n",
      "training time: 648.4355347156525\n",
      "\n",
      "evaluating model...\n",
      "test loss: 1.0796999931335449e-05, test accuracy: 45.28333333333333\n",
      "training history saved\n",
      "\n",
      "training iteration: 4 of 5\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.02726870044734743, training accuracy: 34.022222222222226\n",
      "epoch: 1, validation loss: 1.684909396701389e-05, validation accuracy: 41.934444444444445\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.024584368137518565, training accuracy: 41.34444444444444\n",
      "epoch: 2, validation loss: 1.0174375110202365e-05, validation accuracy: 45.815555555555555\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 0.02373238027493159, training accuracy: 43.76888888888889\n",
      "epoch: 3, validation loss: 1.2832852204640706e-05, validation accuracy: 47.88111111111111\n",
      "\n",
      "epoch: 4, training loss: 0.023154339598284827, training accuracy: 45.782222222222224\n",
      "epoch: 4, validation loss: 1.631547874874539e-05, validation accuracy: 50.30222222222222\n",
      "\n",
      "epoch: 5, training loss: 0.022796317372057173, training accuracy: 46.55888888888889\n",
      "epoch: 5, validation loss: 1.5123456054263644e-05, validation accuracy: 51.093333333333334\n",
      "\n",
      "epoch: 6, training loss: 0.02242658803595437, training accuracy: 47.63333333333333\n",
      "epoch: 6, validation loss: 9.548824363284642e-06, validation accuracy: 49.227777777777774\n",
      "model saved\n",
      "\n",
      "epoch: 7, training loss: 0.02222070041100184, training accuracy: 48.30444444444444\n",
      "epoch: 7, validation loss: 1.362767219543457e-05, validation accuracy: 51.26\n",
      "\n",
      "epoch: 8, training loss: 0.02208180437352922, training accuracy: 48.60777777777778\n",
      "epoch: 8, validation loss: 1.4284311400519476e-05, validation accuracy: 52.32111111111111\n",
      "\n",
      "epoch: 9, training loss: 0.021851379742887284, training accuracy: 49.23222222222222\n",
      "epoch: 9, validation loss: 1.4433648851182726e-05, validation accuracy: 52.67444444444445\n",
      "\n",
      "epoch: 10, training loss: 0.021690661842955483, training accuracy: 49.85333333333333\n",
      "epoch: 10, validation loss: 1.2672348817189534e-05, validation accuracy: 54.40555555555556\n",
      "\n",
      "training finished\n",
      "\n",
      "{'loss_train': [0.02726870044734743, 0.024584368137518565, 0.02373238027493159, 0.023154339598284827, 0.022796317372057173, 0.02242658803595437, 0.02222070041100184, 0.02208180437352922, 0.021851379742887284, 0.021690661842955483], 'accuracy_train': [34.022222222222226, 41.34444444444444, 43.76888888888889, 45.782222222222224, 46.55888888888889, 47.63333333333333, 48.30444444444444, 48.60777777777778, 49.23222222222222, 49.85333333333333], 'loss_val': [1.684909396701389e-05, 1.0174375110202365e-05, 1.2832852204640706e-05, 1.631547874874539e-05, 1.5123456054263644e-05, 9.548824363284642e-06, 1.362767219543457e-05, 1.4284311400519476e-05, 1.4433648851182726e-05, 1.2672348817189534e-05], 'accuracy_val': [41.934444444444445, 45.815555555555555, 47.88111111111111, 50.30222222222222, 51.093333333333334, 49.227777777777774, 51.26, 52.32111111111111, 52.67444444444445, 54.40555555555556], 'last_save': 6}\n",
      "training time: 646.7024042606354\n",
      "\n",
      "evaluating model...\n",
      "test loss: 9.700216187371148e-06, test accuracy: 49.12555555555556\n",
      "training history saved\n",
      "\n",
      "training iteration: 5 of 5\n",
      "starting training...\n",
      "epoch: 1, training loss: 0.0276544993824429, training accuracy: 32.486666666666665\n",
      "epoch: 1, validation loss: 1.3615507549709744e-05, validation accuracy: 42.31111111111111\n",
      "model saved\n",
      "\n",
      "epoch: 2, training loss: 0.024922782140307957, training accuracy: 40.36555555555555\n",
      "epoch: 2, validation loss: 1.0356321599748399e-05, validation accuracy: 45.757777777777775\n",
      "model saved\n",
      "\n",
      "epoch: 3, training loss: 0.023910824579662746, training accuracy: 43.382222222222225\n",
      "epoch: 3, validation loss: 1.5874364640977648e-05, validation accuracy: 49.215555555555554\n",
      "\n",
      "epoch: 4, training loss: 0.02334134710232417, training accuracy: 45.208888888888886\n",
      "epoch: 4, validation loss: 1.5245001845889622e-05, validation accuracy: 49.92\n",
      "\n",
      "epoch: 5, training loss: 0.022916765365335677, training accuracy: 46.425555555555555\n",
      "epoch: 5, validation loss: 1.3973768552144369e-05, validation accuracy: 50.68555555555555\n",
      "\n",
      "epoch: 6, training loss: 0.022664323268996346, training accuracy: 47.26444444444444\n",
      "epoch: 6, validation loss: 1.5201980537838406e-05, validation accuracy: 51.84111111111111\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[12], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m train_with_different_parameters(\u001B[38;5;241m5\u001B[39m, Net, \u001B[38;5;241m10\u001B[39m, train_dat, val_dat, test_dat, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcuda\u001B[39m\u001B[38;5;124m'\u001B[39m, batch_size, lrs\u001B[38;5;241m=\u001B[39m[i\u001B[38;5;241m/\u001B[39m\u001B[38;5;241m500\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m i \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;241m1\u001B[39m,\u001B[38;5;241m6\u001B[39m)])\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project\\training_pipeline.py:78\u001B[0m, in \u001B[0;36mtrain_with_different_parameters\u001B[1;34m(n, init_model, epochs, train_dataloader, val_dataloader, test_dataloader, device, batchsize, lrs, dropouts, betas)\u001B[0m\n\u001B[0;32m      0\u001B[0m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project\\training_pipeline.py:44\u001B[0m, in \u001B[0;36mrepeat_training\u001B[1;34m(n, init_model, lr, model_path, history_path, epochs, train_dataloader, val_dataloader, test_dataloader, device, dropout, betas)\u001B[0m\n\u001B[0;32m     42\u001B[0m start_time \u001B[38;5;241m=\u001B[39m time\u001B[38;5;241m.\u001B[39mtime()\n\u001B[0;32m     43\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstarting training...\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m---> 44\u001B[0m training_history \u001B[38;5;241m=\u001B[39m train(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device,\n\u001B[0;32m     45\u001B[0m                          model_path_idx)\n\u001B[0;32m     46\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtraining finished\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28mprint\u001B[39m(training_history)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project\\training_functions.py:52\u001B[0m, in \u001B[0;36mtrain\u001B[1;34m(epochs, model, train_dataloader, val_dataloader, optimizer, criterion, device, model_path)\u001B[0m\n\u001B[0;32m     49\u001B[0m last_save \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m     51\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m---> 52\u001B[0m     train_accuracy, train_avg_loss \u001B[38;5;241m=\u001B[39m training_epoch(model, train_dataloader, optimizer, criterion, device)\n\u001B[0;32m     53\u001B[0m     train_accuracy_list\u001B[38;5;241m.\u001B[39mappend(train_accuracy)\n\u001B[0;32m     54\u001B[0m     train_loss_list\u001B[38;5;241m.\u001B[39mappend(train_avg_loss)\n",
      "File \u001B[1;32mD:\\Studia\\semestr8\\deep_learning_project\\training_functions.py:14\u001B[0m, in \u001B[0;36mtraining_epoch\u001B[1;34m(model, dataloader, optimizer, criterion, device)\u001B[0m\n\u001B[0;32m     11\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(output, y)\n\u001B[0;32m     13\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m---> 14\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[0;32m     15\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     17\u001B[0m epoch_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\_tensor.py:581\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    571\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    572\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    573\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    574\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    579\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    580\u001B[0m     )\n\u001B[1;32m--> 581\u001B[0m torch\u001B[38;5;241m.\u001B[39mautograd\u001B[38;5;241m.\u001B[39mbackward(\n\u001B[0;32m    582\u001B[0m     \u001B[38;5;28mself\u001B[39m, gradient, retain_graph, create_graph, inputs\u001B[38;5;241m=\u001B[39minputs\n\u001B[0;32m    583\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m _engine_run_backward(\n\u001B[0;32m    348\u001B[0m     tensors,\n\u001B[0;32m    349\u001B[0m     grad_tensors_,\n\u001B[0;32m    350\u001B[0m     retain_graph,\n\u001B[0;32m    351\u001B[0m     create_graph,\n\u001B[0;32m    352\u001B[0m     inputs,\n\u001B[0;32m    353\u001B[0m     allow_unreachable\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    354\u001B[0m     accumulate_grad\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m,\n\u001B[0;32m    355\u001B[0m )\n",
      "File \u001B[1;32m~\\anaconda3\\Lib\\site-packages\\torch\\autograd\\graph.py:825\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    823\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    824\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 825\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m Variable\u001B[38;5;241m.\u001B[39m_execution_engine\u001B[38;5;241m.\u001B[39mrun_backward(  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m         t_outputs, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    827\u001B[0m     )  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    828\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    829\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dropout test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train_with_different_parameters(5, Net, 10, train_dat, val_dat, test_dat, 'cuda', batch_size, dropouts=[i/10 for i in range(3,8)])"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Betas tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "train_with_different_parameters(5, Net, 10, train_dat, val_dat, test_dat, 'cuda', batch_size, betas=[(1-i/10, 1-i/1000) for i in range(2,6)])"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
